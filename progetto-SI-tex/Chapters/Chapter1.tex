\chapter{Reti Neurali Artificiali: le basi} % Main chapter title
\label{Capitolo1} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
%variables to define path to images
\def \path {Figures/C1}
\def \teoria {Figures/teoria}

%--------------------------------------------------------------------%--------------------
%	SECTION 1
%--------------------
%--------------------------------------------------------------------

\section{Breve introduzione}
\label{sec:intro}
%COSA SONO LE RETI NEURALI ARTIFICIALI
Una rete neurale artificiale – chiamata normalmente solo rete neurale (in inglese \emph{Neural Network}) – è
un modello di calcolo adattivo, ispirato ai principi di funzionamento del sistema nervoso degli organismi evoluti che secondo l'approccio connessionista\parencite{WConnessionismo} possiede una complessità non descrivibile con i metodi simbolici.  
La caratteristica fondamentale di una rete neurale è che essa è capace di acquisire conoscenza modificando la propria struttura in base alle informazioni esterne (i dati in ingresso) e interne (tramite le connessioni) durante il processo di apprendimento. Le informazioni sono immagazzinate nei parametri della rete, in particolare, nei pesi associati alle connessioni. 
Sono strutture non lineari in grado di simulare relazioni complesse tra
ingressi e uscite che altre funzioni analitiche non sarebbero in grado di fare. 


L'unità base di questa rete è il neurone artificiale introdotto per la prima volta da McCulloch e
Pitts nel 1943 (fig. \ref{fig:neuron}).


\begin{figure}[h!]
 \centering
 \includegraphics[width=1.0\textwidth]{\teoria/NeuronePitts.png}
 \caption{Modello di calcolo di un neurone (a sinistra) e schema del neurone artificiale (a destra)}
 \label{fig:neuron}
\end{figure}

Si tratta di un'unità di calcolo a N ingressi e 1 uscita. Come si può vedere dall'immagine a
sinistra gli ingressi rappresentano le terminazioni sinaptiche, quindi sono le uscite di altrettanti
neuroni artificiali. A ogni ingresso corrisponde un peso sinaptico $w$, che stabilisce quanto quel
collegamento sinaptico influisca sull'uscita del neurone. Si determina quindi il potenziale del neurone facendo una somma degli ingressi, pesata secondo i pesi $w$. \\
A questa viene applicata una funziona di trasferimento non lineare: 
\begin{equation}
 f(x) = H(\sum_{i}(w_i x_i))
\end{equation} 
ove $H$ è la funzione gradino di Heaviside \parencite{WHeaviside}. Vi sono, come vedremo, diverse altre funzioni non lineari tipicamente utilizzate come funzioni di attivazioni dei neuroni. 
Nel '58 Rosenblatt propone il modello di \emph{Percettrone} rifinendo il modello di neurone a soglia, aggiungendo un termine di \emph{bias} e un algoritmo di apprendimento basato sulla minimizzazione dell'errore, cosiddetto \emph{error back-propagation}\parencite{WPercettrone}.
\begin{equation}
 f(x) = H(\sum_{i}(w_i x_i)+b),\quad ove \quad b = bias \\
\end{equation}
\begin{equation} 
 w_i(t+1) = w_i(t)+\eta \delta x_i(t)
\end{equation}
dove $\eta$ è una costante di apprendimento strettamente positiva che regola la velocità di apprendimento, detta \emph{learning rate} e $\delta$ è la discrepanza tra l'output desiderato e l'effettivo output della rete. 

Il percettrone però era in grado di imparare solo funzioni linearmente separabili. Una maniera per oltrepassare questo limite è di combinare insieme le risposte di più percettroni, secondo architetture multistrato. 
%--------------------------------------------------------------------%--------------------
%	SECTION 2
%--------------------
%--------------------------------------------------------------------

\section{Multi-layer Perceptron}
\label{sec:mlp}
Il Multi-layer Perceptron (\textit{MLP}) o percettrone multi-strato è un tipo di rete feed-forward che mappa un set di input ad un set di output. È la naturale estensione del percettrone singolo e permette di distinguere dati non linearmente separabili.

\begin{figure}[h!]
 \centering
 \includegraphics[width=1.0\textwidth]{\teoria/multilayer.png}
 \caption{Struttura di un percettrone multistrato con un solo strato nascosto}
 \label{fig:multilayer}
\end{figure}


Il \emph{mlp} possiede le seguenti caratteristiche: 
\begin{itemize}
\item ogni neurone è un percettrone come quello descritto nella sezione \ref{sec:intro}. Ogni unità possiede quindi una propria funzione d'attivazione non lineare.
\item a ogni connessione tra due neuroni corrisponde un peso sinaptico $w$
\item è formato da 3 o più strati. In \ref{fig:multilayer} è mostrato un MLP con uno strato di input; un solo strato nascosto (o \emph{hidden layer}; ed uno di output.) 
\item l'uscita di ogni neurone dello strato precedente è l'ingresso per ogni neurone dello
strato successivo. È quindi una rete \emph{completamente connessa}. Tuttavia, si possono
disconnettere selettivamente settando il peso sinaptico $w$ a 0.
\item la dimensione dell'input e la dimensione dell'output dipendono dal numero di
neuroni di questi due strati. Il numero di neuroni dello strato nascosto è invece
indipendente, anche se influenza di molto le capacità di apprendimento della rete. 
\end{itemize}
%non linearità 
Se ogni neurone utilizzasse una funzione lineare allora si potrebbe ridurre l'intera rete ad una composizione di funzioni lineari. Per questo - come detto prima - ogni neurone possiede una funzione di attivazione non lineare. 

%black box
\subsection{Strati Nascosti}
I cosiddetti \emph{hidden layers} sono una parte molto interessante della rete. Per il teorema di
approssimazione universale\parencite{WApprox}, \cite{WApprox} \parencite{WConnessionismo} una rete con un singolo strato nascosto e un numero finiti di
neuroni, può essere addestrata per approssimare una qualsiasi funzione continua su uno spazio compatto di $\mathbb{R}^n$. In altre parole, un singolo strato nascosto è abbastanza potente da imparare un ampio numero di funzioni. Precisamente, una rete a 3 strati è in grado di separare regioni convesse con un numero di lati $\leqslant$ numero neuroni nascosti. 

Reti con un numero di strati nascosti maggiore di 3 vengono chiamate reti neurali profonde o \emph{deep neural network}; esse sono in grado di separare regioni qualsiasi, quindi di approssimare praticamente qualsiasi funzione. Il primo e l’ultimo strato devono avere un numero di neuroni pari alla dimensione dello spazio di ingresso e quello di uscita. Queste sono le terminazioni della \emph{"black box"} che rappresenta la funzione che vogliamo approssimare. 

L'aggiunta di ulteriori strati non cambia \emph{formalmente} il numero di funzioni che si possono approssimare; tuttavia vedremo che nella pratica un numero elevato di strati migliori di gran lunga le performance della rete su determinati task, essendo gli hidden layers gli strati dove la rete memorizza la propria rappresentazione astratta dei dati in ingresso. Nel capitolo 4 vedremo un'architettura all'avanguardia con addirittura 152 strati.
 
%--------------------------------------------------------------------%--------------------
%	SECTION 3
%--------------------
%--------------------------------------------------------------------

\section{Caso di studio: prevedere il profitto di un ristorante}
%%%  30 Coperti - 11 Mesi all'anno
%%%  20 coperti - 38-42 ore di apertura a settimana 
%%%  Profitto in % = Ricavo - Spesa, According to the Restaurant Resource Group, average profit margins for restaurants range from 2 to 6 percent. 
%%% 
Prendendo spunto dalla traccia d'esame di Sistemi Intelligenti M del 2 Aprile 2009:
\begin{quote}
\textit{"Loris è figlio della titolare di una famoso spaccio di piadine nel Riminese e sta tornando in Italia
dopo aver frequentato con successo un prestigioso Master in Business Administration ad Harvard, a
cui si è iscritto inseguendo il sogno di esportare in tutto il mondo la piadina romagnola. Nel lungo
viaggio in prima classe, medita su come presentare alla mamma, che sa essere un tantino restia alle
innovazioni, il progetto di aprire un ristorantino a New York City."}
\end{quote}
Loris ha esportato con successo la piadina a NY, si veda \parencite{WGradisca} \href{www.gradiscanyc.com} ma col passare degli anni ha notato alcuni problemi e vuole utilizzare di nuovo le sue brillanti capacità analitiche per migliorare il profitto del suo ambizioso ristorante. \\
I problemi sono 2: 
\begin{enumerate}
\item il ristorante è conosciuto ormai - si sa che tutti vogliono mangiare italiano - ma il numero dei coperti era rimasto a 22, come quelli iniziali; 
\item gli orari di apertura sono troppo lunghi e vi sono alcune zone morte dove il costo di mantenere aperto il ristorante è maggiore rispetto al ricavo dei pochi clienti che si siedono a mangiare durante quelle ore; 
\end{enumerate}
Secondo la National Restaurant Association\parencite{WProfit} \parencite{WRRG} il profitto medio lordo annuo di un ristorante negli Stati Uniti varia dal 2 al 6\%. Così Loris ha collezionato alcuni dati riguardo gli ultimi anni e - attratto da tutta quest'entusiasmo attorno alle reti neurali - decide di provare ad utilizzarle per trovare il trade-off ottimale di coperti e di orari di apertura settimanali per massimizzare il profitto del suo ristorante. 

%--------------------------------------------------------------------%--------------------
%	SECTION 4
%--------------------
%--------------------------------------------------------------------

\section{Implementazione da zero di un MLP}
%Parlare brevemente del caso di studio
Per il suddetto caso di studio si è implementato da zero un percettrone multistrato a 3 strati come quello illustrato in sezione \ref{sec:mlp}. Vediamo qui di seguito le varie parti da implementare passo passo per costruire un MLP, addestrarlo e verificare che l'addestramento sia stato eseguito in maniera corretta. Il progetto è realizzato in Lua, per utilizzare il framework per il \emph{Machine Learning} \textbf{Torch} e mantenere le consistenza con gli altri capitoli, nei quali si userà ancora Torch per addestrare reti neurali molto più complesse. 
\subsection{Dataset e Architettura}
Nei vari anni, Loris ha cambiato le due variabili in gioco annotando di volta in volta i risultati. Siccome i coperti erano troppo pochi e le file d'attesa erano troppo lunghe, il ristorante perdeva alcuni clienti. Quindi Loris ha portato i coperti a 25 e diminuendo le ore settimanali a 38, ed i profitti sono aumentati. Tuttavia, non era raro che ancora qualche cliente dovesse aspettare in piedi per troppo tempo (si sa la vita a NY è frenetica), finendo poi per scegliere un ristorante adiacente. Inoltre, aveva diminuito le ore di troppo; nel weekend i clienti arrivavano fino a tardi, quindi rimanere aperti un'ora in più sarebbe stato lungimirante. Così, dopo l'allargamento della sala principale, ha aggiunto altri coperti ed aumentato le ore settimanali a 40, segnando un record personale di $4.4\%$ di profitti annui. \\

Quindi, i dati in ingresso ed in uscita, in $X$ e $Y$ rispettivamente sono:
\[ 
X = \begin{pmatrix}
22 & 42\\ 
25 & 38 \\ 
30 & 40
\end{pmatrix} 
%
Y = \begin{pmatrix}
2.8\\ 
3.4 \\ 
4.4
\end{pmatrix} 
\]
Osservando le dimensioni dei dati si nota che la rete deve avere 2 input e dare in uscita 1 output, che chiameremo $\hat{y}$, in contrapposizione a $y$ che è l'uscita desiderata. Per quanto detto nella sezione \ref{sec:mlp}, il MLP deve avere 2 neuroni nello strato di ingresso ed 1 solo in uscita. Inoltre, avrà uno strato nascosto con 3 neuroni. La dimensione di ogni strato fa parte di un insieme di parametri che viene deciso "a mano" sperimentando, i cosiddetti \emph{hyperparameters}. Questi parametri non vengono aggiornati durante l'addestramento - come i pesi della rete - ma vengono decisi a priori. \\In figura \ref{fig:mlp} è mostrata l'architettura generale della nostra rete. 

\begin{figure}[h!]
 \centering
 \includegraphics[width=1.0\textwidth]{\path/MLP-Profitto.png}
 \caption{Architettura del percettrone multistrato per la previsione dei profitti}
 \label{fig:mlp}
\end{figure}

Di seguito gli snippet di codice per la definizione dei dati e dell'architettura della rete secondo lo schema appena presentato. 

\begin{lstlisting}[language={[5.2]Lua}]
----------------------- Part 1 ----------------------------
th = require 'torch'
bestProfit = 6.0
-- X = (num coperti, ore di apertura settimanali), y = profitto lordo annuo in percentuale
torch.setdefaulttensortype('torch.DoubleTensor')
X = th.Tensor({{22,42}, {25,38}, {30,40}})
y = th.Tensor({{2.8},{3.4},{4.4}})

--normalize
normalizeTensorAlongCols(X)
y = y/bestProfit

\end{lstlisting}

\begin{lstlisting}[language={[5.2]Lua}]
----------------------- Part 2 ----------------------------
--creating the NN class in Lua, using a nice class utility
require 'class'

Neural_Network = class(function(net, inputs, hiddens, outputs)
      net.inputLayerSize = inputs
      net.hiddenLayerSize = hiddens
      net.outputLayerSize = outputs
      net.W1 = th.randn(net.inputLayerSize, net.hiddenLayerSize)
      net.W2 = th.randn(net.hiddenLayerSize, net.outputLayerSize)
   end)
\end{lstlisting}

\subsection{Forward Propagation}

%%% MULTI-COLUMN table for variables 
\begin{table}[h!]
\caption{Variabili usate nel testo e nel codice}
\label{tab:variabili}
\begin{center}
\begin{tabular}{ |p{3cm}||p{3cm}|p{3cm}|p{3cm}|  }
 \hline
 \multicolumn{4}{|c|}{\textbf{Variabili}} \\
 \hline
 \textbf{S. Codice} & \textbf{S. Matematico} & \textbf{Definizione} & \textbf{Dimensione}\\
 \hline
 X	& $X$	&Esempi, 1 per riga&	\makecell{(numEsempi, \\inputLayerSize)}\\
 \hline
 y&	$y$	& uscita desiderata	& \makecell{(numEsempi, \\outputLayerSize)}\\ 
 \hline
 W1 & $W^{(1)}$	& Pesi layer 1&	\makecell{(inputLayerSize, \\hiddenLayerSize)}\\
 \hline
 W2	& $W^{(2)}$   & Pesi layer 2&	(hiddenLayerSize, outputLayerSize)\\
 \hline
 z2 & $z^{(2)}$	& Input layer 2& \makecell{(numEsempi, \\hiddenLayerSize)}\\
 \hline
 a2 & $a^{(2)}$	& Uscita layer 2& \makecell{(numEsempi, \\hiddenLayerSize)}\\
 \hline
 z3 & $z^{(3)}$	& Input layer 3& \makecell{(numEsempi, \\outputLayerSize)}\\
  \hline
 \end{tabular}
 \end{center}
 \end{table}
Nella tabella \ref{tab:variabili} sono elencate le variabili della rete. Gli input dei layer indicati con $z$ possono anche essere chiamati "attività dei layer" (indicando l'attività sulle loro sinapsi); e $a^{(2)}$ indica l'uscita del neurone dopo aver applicato la sommatoria e la funzione di attivazione sulle attività provenienti dal layer precedente.

Per muovere i dati in parallelo attraverso la rete si usa la moltiplicazione fra matrici, per questo è molto comodo usare framework che supportano operazioni fra matrici come \emph{Torch, Numpy o Matlab}. Per prima cosa, gli input del tensore $X$ devono essere moltiplicati e sommati con i pesi del primo layer $W^{(1)}$, ottenendo l'ingresso per l'hidden layer: 
\begin{equation}
z^{(2)} = XW^{(1)} \tag{1}
\end{equation}
Si noti che $z^{(2)}$ è di dimensione 3x3, essendo $X$ e $W^{(1)}$ di dimensione 3x2 e 2x3 rispettivamente. \\
Ora bisogna applicare la funzione di attivazione a $z^{(2)}$. Vi sono diverse funzioni di attivazione utilizzate per le reti neurali. Una delle prime a diventare popolare fu la funzione \emph{sigmoide}\parencite{WSigmoid}, utilizzata per questa rete. Vedremo nei capitoli successivi funzioni più efficaci.
\begin{equation}
a^{(2)} = f(z^{(2)}) \tag{2},\quad ove \quad f=sigmoide
\end{equation}
Per completare la \emph{forward propagation}, bisogna seguire lo stesso procedimento per lo strato di output: sommare i contributi provenienti dall'hidden layer ed applicare la sigmoide: 
\begin{center}
\begin{align*}
z^{(3)} = a^{(2)}W^{(2)} \tag{3}\\
\hat{y} = f(z^{(3)}) \tag{4}
\end{align*}
\end{center}
Essendo $a^{(2)}$ di dimensione 3x3 e $W^{(2)}$ 3x1 l'output $\hat{y}$ sarà anch'esso di dimensione 3x1, risultando quindi in una previsione per ogni esempio in ingresso. \\
Si noti come la moltiplicazione fra matrici renda tutto esprimibile in poche righe di codice. 
\begin{lstlisting}[language={[5.2]Lua}]
--Note: I didn't implement manually the sigmoid function as Torch has one built-in.
--define a forward method
function Neural_Network:forward(X)
   --Propagate inputs though network
   self.z2 = th.mm(X, self.W1) --matrix multiplication
   self.a2 = th.sigmoid(self.z2)
   self.z3 = th.mm(self.a2, self.W2)
   yHat = th.sigmoid(self.z3)
   return yHat
end
\end{lstlisting}
\subsection{Backpropagation}
Come si fa ad addestrare una rete multistrato con diversi neuroni per strato, ognuno dei quali con uscita non lineare? Tramite l'algoritmo di \emph{backpropagation of errors}, scoperto da Rumelhart-Hinton-Williams nel 1985. 

Non si può introdurre l'algoritmo di \emph{"backprop"} senza prima spiegare il concetto di funzione di costo (o \emph{loss function}). Nelle reti neurali (e più specificatamente nell'apprendimento supervisionato\parencite{WSupervised}), la funzione di costo misura la discrepanza tra l'uscita desiderata e l'effettivo output della rete. È quindi una misura dell'errore della rete, per cui l'obiettivo dell'apprendimento è diminuire questa funzione. Come per la funzione di attivazione, anche in questo caso ci sono ampie possibilità di scelta \parencite{WLoss} a seconda del task su cui la rete viene addestrata. \\
E di nuovo, come per la funzione di attivazione, si è scelta una delle funzione di costo più popolari: l'errore quadratico medio. 
\begin{equation}
J = \sum_{j=1}^{n} \frac{1}{2} (y-\hat{y})^2} \tag{5}
\end{equation}

La \emph{backprop} ha alcuni requisiti: 
\begin{itemize}
\item Reti stratificate 
\item Ingressi a valori reali $\in [0,1]$
\item Neuroni non lineari con funzione di uscita sigmoidale (o altra fz. di attivazione derivabile)
\end{itemize} 
Sotto queste condizioni l'algoritmo sfrutta la regola della catena\parencite{WChain} per la derivazione di funzione composte, per calcolare il gradiente della \emph{funzione di costo}. I pesi della rete vengono quindi aggiornati secondo la \emph{discesa del gradiente} (figura\ref{fig:gradDescend}); ovvero variano in maniera tale da minimizzare la funzione di costo $J$. 
\begin{figure}[h!]
 \centering
 \includegraphics[width=1.0\textwidth]{\teoria/gradientbased.png}
 \caption{Cercare il minimo di una fz. seguendo la discesa del gradiente}
 \label{fig:gradDescend}
\end{figure}

Viene chiamato \emph{backward propagation of errors} poiché l'errore calcolato a partire dall'output della rete viene distribuito in maniera proporzionale all'indietro, su tutti i neuroni della rete. È importante quindi, spezzare il calcolo del gradiente dell'errore in derivate parziali, dall'ultimo strato fino al primo, e poi combinarle insieme. 

Si noti che le equazioni (1-5) formano una un'unica equazione che lega $J$ a $X, y, W^{(1)}, W^{(2)}$. Tenendo questo in mente, si applica la regola della catena. \\ 
%% mettere la formula completa da spezzare in passaggi %% 
Partendo dal fattore riguardante lo strato di output si ha: 
$$
\frac{\partial J}{\partial W^{(2)}} = \sum \frac{\partial \frac{1}{2}(y-\hat{y})^2}{\partial W^{(2)}}
$$
Sviluppando i calcoli si ottiene: 
$$
\frac{\partial J}{\partial W^{(2)}} = -(y-\hat{y}) \frac{\partial \hat{y}}{\partial W^{(2)}}
$$
L'equazione (4) indica che $\hat{y}$ è la funzione di attivazione di $z^{(3)}$. Da cui: 
$$
\frac{\partial J}{\partial W^{(2)}} = 
-(y-\hat{y})
\frac{\partial \hat{y}}{\partial z^{(3)}}  
\frac{\partial z^{(3)}}{\partial W^{(2)}}
$$
Il 2° membro dell'equazione è semplicemente la derivata della funzione di attivazione sigmoide: 
\begin{align*}
f(z) = \frac{1}{1+e^{-z}}\\
f^\prime(z) = \frac{e^{-z}}{(1+e^{-z})^2}
\end{align*}
Definiamo quindi la derivata della funzione sigmoid in Lua: 
%% qui codice %% 

%% qui grafico uguale al iPython %% 
Quindi l'equazione così ottenuta è: 
$$
\frac{\partial J}{\partial W^{(2)}}= 
-(y-\hat{y}) f^\prime(z^{(3)}) \frac{\partial z^{(3)}}{\partial W^{(2)}}
$$
 
Infine, dobbiamo trovare dz3dW2, che rappresenta la variazione dell'attività del terzo layer rispetto ai pesi del secondo layer. Richiamando l'equazione (3): 
$$
z^{(3)} = a^{(2)}W^{(2)} \tag{3}\\
$$





\subsection{Verifica numerica del gradiente}
\subsection{Addestramento}

%--------------------------------------------------------------------%--------------------
%	SECTION 5
%--------------------
%--------------------------------------------------------------------

\section{Ottimizzazione: diverse tecniche}
%SGD ASGD LBGFS ADAM 
%INSERIRE GRAFICI 


%--------------------------------------------------------------------%--------------------
%	SECTION 6
%--------------------
%--------------------------------------------------------------------
\section{Overfitting: come rilevarlo e risolverlo}



%--------------------------------------------------------------------%--------------------
%	SECTION 7
%--------------------
%--------------------------------------------------------------------

\section{Risultati}
