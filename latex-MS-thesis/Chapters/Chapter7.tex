\chapter{Conclusioni} 
Questa attività progettuale ha permesso sia di testare sul campo che di fornire un'opportunità di studio ed analisi ad ampio spettro delle reti neurali artificiali, che hanno fatto tanto parlare di sé negli ultimi anni. Dapprima, si sono esposte le basi teoriche delle reti neurali che gettano le loro radici a più di mezzo secolo fa; poi si è implementato da zero un percettrone multi-strato cercando di "demistificarne" il funzionamento interno, essendo quest'ultimo poco intuitivo. Particolare enfasi è stata data alla spiegazione dell'algoritmo che è alla base dell'apprendimento delle reti, la \textbf{backpropagation of errors}. Dopodiché è stata fornita una panoramica sull'architettura delle \textbf{Convolutional Neural Networks}. Considerate lo stato dell'arte per la visione artificiale, hanno confermato le aspettative durante i test sui diversi dataset. Nel confronto fra le due architetture è emerso che avere un maggior numero di strati di convoluzione dona alla rete una maggiore potenza espressiva ed una rimarchevole capacità di astrazione e comprensione dei soggetti nelle immagini. Infine, il \textbf{transfer-learning} si è dimostrato una strategia di successo per ottenere classificatori ottimizzati per dataset arbitrari, anche piccoli. 
\\
Il framework \textbf{Torch} ha mantenuto le sue promesse sulla prototipazione flessibile e veloce. È un framework che può contare su un largo ecosistema di librerie guidate dalla comunità di ricercatori e l'astrazione che fornisce semplifica molto la progettazione e l'ottimizzazione delle reti, mantenendo al tempo stesso l'elasticità che i ricercatori necessitano per costruire modelli bleeding-edge. Tuttavia, non è facile eseguire il debugging di reti molto complesse ed, in un campo dove il trial-and-error è il pane quotidiano, sembra che ci possa essere ancora un margine di miglioramento. 

Si noti, infine, che il progetto poteva essere realizzato anche con una delle molte altre librerie per il Deep Learning (TensorFlow, Keras, Caffe, DL4J) le quali presentano ciascuna le proprie peculiarità. Vale certamente la pena seguirne gli sviluppi e sperimentarne l'utilizzo, magari con applicazioni anche in ambiti diversi. Tutto ciò dimostra quante alternative il panorama del deep learning abbia da offrire e quanto questo campo sia in crescita esponenziale.








